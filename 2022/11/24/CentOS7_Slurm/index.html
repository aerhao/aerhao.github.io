<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>CentOS7.9 install Slurm | AI HPC in doing we learn!</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="计算节点使用无配置(configless)模式启动slurmd服务123456789101112项目设备：sda盘安装操作系统标准分区sdb盘*T，可以挂载&#x2F;home目录，普通用户家目录使用安装系统：[root@admin ~]# cat &#x2F;etc&#x2F;redhat-releaseCentOS Linux release 7.9.2009 (Core)[root@admin ~]# uname -r3">
<meta property="og:type" content="article">
<meta property="og:title" content="CentOS7.9 install Slurm">
<meta property="og:url" content="http://example.com/2022/11/24/CentOS7_Slurm/index.html">
<meta property="og:site_name" content="AI HPC in doing we learn!">
<meta property="og:description" content="计算节点使用无配置(configless)模式启动slurmd服务123456789101112项目设备：sda盘安装操作系统标准分区sdb盘*T，可以挂载&#x2F;home目录，普通用户家目录使用安装系统：[root@admin ~]# cat &#x2F;etc&#x2F;redhat-releaseCentOS Linux release 7.9.2009 (Core)[root@admin ~]# uname -r3">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-11-24T06:07:57.575Z">
<meta property="article:modified_time" content="2022-11-24T06:07:57.575Z">
<meta property="article:author" content="张东豪 zhangdonghao678@163.com">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="AI HPC in doing we learn!" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.2"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">AI HPC in doing we learn!</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-CentOS7_Slurm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2022/11/24/CentOS7_Slurm/" class="article-date">
  <time datetime="2022-11-24T06:07:57.575Z" itemprop="datePublished">2022-11-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      CentOS7.9 install Slurm
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="计算节点使用无配置-configless-模式启动slurmd服务"><a href="#计算节点使用无配置-configless-模式启动slurmd服务" class="headerlink" title="计算节点使用无配置(configless)模式启动slurmd服务"></a>计算节点使用无配置(configless)模式启动slurmd服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">项目设备：</span><br><span class="line">sda盘安装操作系统标准分区</span><br><span class="line">sdb盘*T，可以挂载/home目录，普通用户家目录使用</span><br><span class="line">安装系统：</span><br><span class="line">[root@admin ~]<span class="comment"># cat /etc/redhat-release</span></span><br><span class="line">CentOS Linux release 7.9.2009 (Core)</span><br><span class="line">[root@admin ~]<span class="comment"># uname -r</span></span><br><span class="line">3.10.0-1160.el7.x86_64</span><br><span class="line">安装软件：</span><br><span class="line">Slurm作业管理系统slurm-22.05.2.tar.bz2</span><br><span class="line">MySQL8</span><br><span class="line">Munge</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h6 id="1、-安装操作系统"><a href="#1、-安装操作系统" class="headerlink" title="1、 安装操作系统"></a>1、 安装操作系统</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">刻录U盘工具ventoy+CentOS7.9</span><br></pre></td></tr></table></figure>

<h6 id="2、-网络、主机名、免密ssh"><a href="#2、-网络、主机名、免密ssh" class="headerlink" title="2、 网络、主机名、免密ssh"></a>2、 网络、主机名、免密ssh</h6><p>ifconfig-ens33是当前的网络连接名</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># vim /etc/sysconfig/network-scripts/ifcfg-ens33</span></span><br><span class="line">[root@admin ~]<span class="comment"># cat /etc/sysconfig/network-scripts/ifcfg-ens33</span></span><br><span class="line">TYPE=Ethernet</span><br><span class="line">BOOTPROTO=dhcp</span><br><span class="line">NAME=ens33</span><br><span class="line">DEVICE=ens33</span><br><span class="line">ONBOOT=<span class="built_in">yes</span></span><br><span class="line">IPADDR=192.168.111.128</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">[root@admin ~]<span class="comment"># systemctl restart network</span></span><br></pre></td></tr></table></figure>

<p>安装net-tools工具方便查看ip</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># yum -y install net-tools</span></span><br><span class="line">[root@admin ~]<span class="comment"># ifconfig</span></span><br></pre></td></tr></table></figure>

<p>关闭防火墙、selinux、NetworkManager</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># systemctl stop firewalld</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl disable firewalld</span></span><br><span class="line">[root@admin ~]<span class="comment"># setenforce 0</span></span><br><span class="line">setenforce: SELinux is disabled</span><br><span class="line">[root@admin ~]<span class="comment"># sed -i &#x27;s/enabled/disabled/g&#x27; /etc/selinux/config</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl stop NetworkManager</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl disable NetworkManager</span></span><br></pre></td></tr></table></figure>

<p>修改名称，改的名称和映射地址的名称一致</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># cat /etc/hostname</span></span><br><span class="line">admin</span><br></pre></td></tr></table></figure>

<p>修改hosts文件地址映射主机名</p>
<p>添加（以实际ip为准，admin是管理节点名称，node1、node2是两台计算节点名称，名称自己定）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># cat /etc/hosts</span></span><br><span class="line">127.0.0.1  localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1     localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.111.128 admin</span><br><span class="line">192.168.111.129 node1</span><br><span class="line">192.168.111.130 node2</span><br></pre></td></tr></table></figure>

<p>配置ssh免密</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># yum install openssl openssh-server -y</span></span><br><span class="line">[root@admin ~]<span class="comment"># vim /etc/ssh/sshd_config</span></span><br><span class="line"><span class="comment">#设置PermitRootLogin=yes</span></span><br><span class="line"><span class="comment"># 设置PasswordAuthentication=yes</span></span><br><span class="line"><span class="comment"># 设置PubkeyAuthentication=yes</span></span><br></pre></td></tr></table></figure>

<p>使用nopasswd脚本配置双向免密</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># cd /opt/nopasswd/</span></span><br><span class="line">[root@admin nopasswd]<span class="comment"># cat hostfile</span></span><br><span class="line">admin</span><br><span class="line">node1</span><br><span class="line">node2</span><br><span class="line">[root@admin nopasswd]<span class="comment"># ./nopasswdroot</span></span><br><span class="line">please input rootpassword:</span><br></pre></td></tr></table></figure>

<p> 配置集群节点双向ssh免密登录</p>
<p>[root@admin nopasswd]# cat nopasswdroot</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">read</span> -p <span class="string">&quot;please input rootpassword: &quot;</span> passwd</span><br><span class="line">ssh-keygen -t dsa -N <span class="string">&quot;&quot;</span> -f <span class="string">&quot;<span class="variable">$HOME</span>/.ssh/id_dsa&quot;</span></span><br><span class="line"><span class="built_in">cp</span> -r <span class="variable">$HOME</span>/.ssh/id_dsa.pub <span class="variable">$HOME</span>/.ssh/authorized_keys</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;StrictHostKeyChecking no&quot;</span> &gt;&gt; <span class="variable">$HOME</span>/.ssh/config</span><br><span class="line"><span class="built_in">chmod</span> 600 <span class="variable">$HOME</span>/.ssh/config</span><br><span class="line"><span class="built_in">chmod</span> 600 <span class="variable">$HOME</span>/.ssh/authorized_keys</span><br><span class="line"><span class="comment">#mkdir $HOME/.vnc/</span></span><br><span class="line"><span class="comment">#echo &quot;111111&quot; &gt;&gt; $HOME/.vnc/passwd</span></span><br><span class="line"><span class="comment">#chmod 600 $HOME/.vnc/passwd</span></span><br><span class="line"><span class="comment">#vncserver :9 -f $HOME/.vnc/passwd</span></span><br><span class="line"><span class="comment">#vncserver -kill :9</span></span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> $(<span class="built_in">cat</span> hostfile)</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">/usr/bin/expect &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">set force_conservative 0  ;# set to 1 to force conservative mode even if</span></span><br><span class="line"><span class="string">			  ;# script wasn&#x27;t run conservatively originally</span></span><br><span class="line"><span class="string">if &#123;$force_conservative&#125; &#123;</span></span><br><span class="line"><span class="string">	set send_slow &#123;1 .1&#125;</span></span><br><span class="line"><span class="string">	proc send &#123;ignore arg&#125; &#123;</span></span><br><span class="line"><span class="string">		sleep .1</span></span><br><span class="line"><span class="string">		exp_send -s -- $arg</span></span><br><span class="line"><span class="string">	&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">set timeout -1</span></span><br><span class="line"><span class="string">spawn scp -rp /root/.ssh $&#123;node&#125;:/root</span></span><br><span class="line"><span class="string">match_max 100000</span></span><br><span class="line"><span class="string">expect -exact &quot;root@$&#123;node&#125;&#x27;s password: &quot;</span></span><br><span class="line"><span class="string">send -- &quot;$passwdr&quot;</span></span><br><span class="line"><span class="string">expect eof</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<h6 id="3、-NFS共享存储"><a href="#3、-NFS共享存储" class="headerlink" title="3、 NFS共享存储"></a>3、 NFS共享存储</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># yum install nfs-utils rpcbind –y</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl enable rpcbind</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl enable nfs-server</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl enable nfs-lock</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl enable nfs-idmap</span></span><br></pre></td></tr></table></figure>

<p>enble换成start来开启服务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># systemctl start rpcbind</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl start nfs-server</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl start nfs-lock</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl start nfs-idmap</span></span><br></pre></td></tr></table></figure>

<p>vim /etc/exports共享管理节点/home目录和/opt目录</p>
<p>#添加 /home 192.168.145.0/24(rw,sync,no_root_squash) </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># cat /etc/exports</span></span><br><span class="line">/home 192.168.111.0/24(rw,<span class="built_in">sync</span>,no_root_squash)</span><br><span class="line">/opt 192.168.111.0/24(rw,<span class="built_in">sync</span>,no_root_squash)</span><br></pre></td></tr></table></figure>

<p>使配置生效</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># exportfs -a</span></span><br></pre></td></tr></table></figure>

<p>共享/home文件夹</p>
<p>客户端node1挂载</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># yum install nfs-utils -y</span></span><br></pre></td></tr></table></figure>

<p>检查服务器共享目录</p>
<p>showmount -e 服务器地址</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># showmount -e admin</span></span><br><span class="line">Export list <span class="keyword">for</span> admin:</span><br><span class="line">/opt 192.168.111.0/24</span><br><span class="line">/home 192.168.111.0/24</span><br></pre></td></tr></table></figure>

<p>开机挂载共享存储</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># vim /etc/rc.local</span></span><br><span class="line">[root@node1 ~]<span class="comment"># cat /etc/rc.local</span></span><br><span class="line">mount -t nfs 192.168.111.128:/home /home</span><br><span class="line">mount -t nfs 192.168.111.128:/opt/  /opt/</span><br><span class="line">[root@node1 ~]<span class="comment"># chmod +x /etc/rc.local</span></span><br></pre></td></tr></table></figure>

<p>客户端客户端node2相同设置挂载</p>
<h6 id="4、-安装配置NIS"><a href="#4、-安装配置NIS" class="headerlink" title="4、 安装配置NIS"></a>4、 安装配置NIS</h6><p>服务端安装</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># yum -y install ypserv ypbind yp-tools setup*</span></span><br></pre></td></tr></table></figure>

<p>设置域名</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># nisdomainname TS10K  # 临时设置</span></span><br><span class="line">[root@admin ~]<span class="comment"># echo &quot;NISDOMAIN=TS10K&quot; &gt;&gt; /etc/sysconfig/network # 永久设置</span></span><br><span class="line">[root@admin ~]<span class="comment"># cat /etc/sysconfig/network</span></span><br><span class="line"><span class="comment"># Created by anaconda</span></span><br><span class="line">NISDOMAIN=TS10K</span><br></pre></td></tr></table></figure>

<p>启动NIS服务和设置开机自启</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># systemctl start ypserv</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl start yppasswdd</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl enable yppasswdd</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl enable ypserv</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl status ypserv</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl status yppasswdd</span></span><br><span class="line">[root@admin ~]<span class="comment"># rpcinfo -u admin ypserv</span></span><br><span class="line">program 100004 version 1 ready and waiting</span><br><span class="line">program 100004 version 2 ready and waiting</span><br></pre></td></tr></table></figure>

<p>NIS服务端初始化：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># /usr/lib64/yp/ypinit -m</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">At this point, we have to construct a list of the hosts <span class="built_in">which</span> will run NIS</span><br><span class="line">servers. admin is <span class="keyword">in</span> the list of NIS server hosts. Please <span class="built_in">continue</span> to add</span><br><span class="line">the names <span class="keyword">for</span> the other hosts, one per line. When you are <span class="keyword">done</span> with the</span><br><span class="line">list, <span class="built_in">type</span> a &lt;control D&gt;.</span><br><span class="line">    next host to add: admin   <span class="comment"># 输入“Ctrl+D”继续执行命令</span></span><br><span class="line">    next host to add:</span><br><span class="line">The current list of NIS servers looks like this:</span><br><span class="line">admin</span><br><span class="line">Is this correct? [y/n: y] y    <span class="comment"># 输入y</span></span><br><span class="line">We need a few minutes to build the databases...</span><br><span class="line"></span><br><span class="line">gmake[1]: Leaving directory `/var/yp/TS10K<span class="string">&#x27;</span></span><br><span class="line"><span class="string">admin has been set up as a NIS master server. </span></span><br><span class="line"><span class="string">Now you can run ypinit -s admin on all slave server.</span></span><br><span class="line"><span class="string">[root@admin ~]#</span></span><br></pre></td></tr></table></figure>

<p>NIS从节点客户端node1 node2输入命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node2 slurm]<span class="comment"># /usr/lib64/yp/ypinit -s admin</span></span><br></pre></td></tr></table></figure>

<p>管理节点admin每次开机时都需要启动这个nis域名，</p>
<p>添加写入/etc/rc.d/rc.local中</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;/usr/bin/nisdomainname TS10K&quot;</span> &gt;&gt; /etc/rc.local</span><br><span class="line">[root@admin ~]<span class="comment"># cat /etc/rc.local</span></span><br><span class="line">/usr/bin/nisdomainname TS10K</span><br></pre></td></tr></table></figure>

<p>客户端安装                   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ypserv ypbind yp-tools</span><br><span class="line">yum -y install setup*</span><br><span class="line">[root@node1 ~]<span class="comment"># yum -y install ypserv ypbind yp-tools setup*</span></span><br><span class="line">[root@node1 ~]<span class="comment"># vim /etc/sysconfig/network</span></span><br><span class="line">[root@node1 ~]<span class="comment"># cat /etc/sysconfig/network</span></span><br><span class="line"><span class="comment"># Created by anaconda</span></span><br><span class="line">NISDOMAIN=TS10K</span><br></pre></td></tr></table></figure>

<p>在客户端的/etc/yp.conf中添加”domain TS10K server admin”</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># vim /etc/yp.conf</span></span><br><span class="line">[root@node1 ~]<span class="comment"># cat /etc/yp.conf</span></span><br><span class="line"><span class="comment"># /etc/yp.conf - ypbind configuration file</span></span><br><span class="line">domain TS10K server admin</span><br><span class="line">[root@node1 ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p>开启ypbind，并设置开机自启。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> ypbind</span><br><span class="line">systemctl start ypbind</span><br><span class="line">systemctl status ypbind</span><br></pre></td></tr></table></figure>

<p>根据经验，需要在计算节点使用</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setup命令--Authentication configuration--[*]Use NIS--Next--Donain:TS10K Server:admin--Quit</span><br></pre></td></tr></table></figure>

<p>启动使用NIS服务，计算节点的账户才会跟NIS服务端同步。</p>
<p>创建普通用户登录做登录测试验证</p>
<p>执行上述操作后，client端才能同步到最新用户信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># useradd test6</span></span><br><span class="line">[root@admin ~]<span class="comment"># passwd test6</span></span><br><span class="line">Changing password <span class="keyword">for</span> user test6.</span><br><span class="line">New password:</span><br><span class="line">BAD PASSWORD: The password is a palindrome</span><br><span class="line">Retype new password:</span><br><span class="line">passwd: all authentication tokens updated successfully.</span><br></pre></td></tr></table></figure>

<p>在admin管理节点提供NIS服务端创建新用户后，需要在/var/yp下执行make，否则客户端没有用户信息。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># cd /var/yp/</span></span><br><span class="line">[root@admin yp]<span class="comment"># make</span></span><br><span class="line">gmake[1]: Entering directory `/var/yp/TS10K<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Updating passwd.byname...</span></span><br><span class="line"><span class="string">Updating passwd.byuid...</span></span><br><span class="line"><span class="string">Updating group.byname...</span></span><br><span class="line"><span class="string">Updating group.bygid...</span></span><br><span class="line"><span class="string">Updating netid.byname...</span></span><br><span class="line"><span class="string">gmake[1]: Leaving directory `/var/yp/TS10K&#x27;</span></span><br></pre></td></tr></table></figure>

<p>普通用户（例如test6）ssh登录计算节点node1、node2需要输入密码，配置普通用户在集群节点之间免密登录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@admin yp]<span class="comment"># su test6</span></span><br><span class="line">Attempting to create directory /home/test6/perl5</span><br><span class="line">[test6@admin yp]$ <span class="built_in">cd</span> /opt/nopasswd/</span><br><span class="line">[test6@admin nopasswd]$ ./nopasswduser</span><br><span class="line">[test6@admin nopasswd]$</span><br><span class="line">[root@admin yp]<span class="comment"># cd /opt/nopasswd/</span></span><br></pre></td></tr></table></figure>

<p>查看普通用户ssh免密配置脚本 cat /opt/nopasswd/nopasswduser</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf <span class="variable">$HOME</span>/.ssh</span><br><span class="line">ssh-keygen -t dsa -N <span class="string">&quot;&quot;</span> -f <span class="string">&quot;<span class="variable">$HOME</span>/.ssh/id_dsa&quot;</span></span><br><span class="line"><span class="built_in">cp</span> -r <span class="variable">$HOME</span>/.ssh/id_dsa.pub <span class="variable">$HOME</span>/.ssh/authorized_keys</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;StrictHostKeyChecking no&quot;</span> &gt;&gt; <span class="variable">$HOME</span>/.ssh/config</span><br><span class="line"><span class="built_in">chmod</span> 600 <span class="variable">$HOME</span>/.ssh/config</span><br><span class="line"><span class="built_in">chmod</span> 600 <span class="variable">$HOME</span>/.ssh/authorized_keys</span><br><span class="line"><span class="comment">#rm -rf $HOME/.vnc</span></span><br><span class="line"><span class="comment">#mkdir $HOME/.vnc</span></span><br><span class="line"><span class="comment">#echo &quot;$password&quot; &gt;&gt; $HOME/.vnc/passwd</span></span><br><span class="line"><span class="comment">#chmod 600 $HOME/.vnc/passwd</span></span><br><span class="line"><span class="comment">#vncserver :9 -f $HOME/.vnc/passwd</span></span><br><span class="line"><span class="comment">#vncserver -kill :9</span></span><br></pre></td></tr></table></figure>

<h6 id="5、-安装munge（管理节点和计算节点）"><a href="#5、-安装munge（管理节点和计算节点）" class="headerlink" title="5、 安装munge（管理节点和计算节点）"></a>5、 安装munge（管理节点和计算节点）</h6><p>MUNGE创建和验证凭据的身份验证服务。它允许一个进程在具有共同用户的主机中验证另一个进程的 UID 和 GID。这些主机形成一个由共享密钥定义的安全域。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">下载munge</span><br><span class="line">https://github.com/dun/munge/releases/tag/munge-0.5.15</span><br><span class="line">[root@admin sourcecode]<span class="comment"># wget https://github.com/dun/munge/releases/download/munge-0.5.15/munge-0.5.15.tar.xz</span></span><br></pre></td></tr></table></figure>

<p>安装rpm构建工具，用来构建rpm安装包</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># yum install -y rpmdevtools gcc bzip2-devel openssl-devel zlib-devel</span></span><br></pre></td></tr></table></figure>

<p>通过构建工具生成rpm安装包</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpmbuild -tb --without verify munge-0.5.15.tar.xz</span><br></pre></td></tr></table></figure>

<p>使用rpm命令安装生成的安装包(构建好的rpm安装包默认在/root/rpbbuild/RPMS/x86_64/)</p>
<p>安装所有munge rpm包</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@admin x86_64]<span class="comment"># pwd</span></span><br><span class="line">/root/rpmbuild/RPMS/x86_64</span><br><span class="line">[root@admin x86_64]<span class="comment"># rpm -ivh munge-</span></span><br><span class="line">munge-0.5.15-1.el7.x86_64.rpm      munge-devel-0.5.15-1.el7.x86_64.rpm</span><br><span class="line">munge-debuginfo-0.5.15-1.el7.x86_64.rpm munge-libs-0.5.15-1.el7.x86_64.rpm</span><br><span class="line">[root@admin x86_64]<span class="comment"># rpm -ivh munge-*</span></span><br><span class="line">rpm -ivh munge*</span><br></pre></td></tr></table></figure>

<p>生成munge.key</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># mungekey -v</span></span><br></pre></td></tr></table></figure>

<p>将生成的munge.key拷贝到计算节点/etc/munge，并更改munge.key的归属用户和组</p>
<p>生成munge.key</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># chmod 0600 /etc/munge/munge.key</span></span><br><span class="line">[root@admin ~]<span class="comment"># chown -R munge.munge /etc/munge/munge.key</span></span><br></pre></td></tr></table></figure>

<p>启动munge服务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># systemctl start munge</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl status munge</span></span><br></pre></td></tr></table></figure>

<p>功能测试munge -n | ssh 客户端主机名 unmunge</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># munge -n | ssh node1 unmunge</span></span><br><span class="line">STATUS:     Success (0)</span><br><span class="line">ENCODE_HOST:   admin (192.168.111.128)</span><br><span class="line">ENCODE_TIME:   2022-08-05 19:31:20 +0800 (1659699080)</span><br><span class="line">DECODE_TIME:   2022-08-05 19:31:21 +0800 (1659699081)</span><br><span class="line">TTL:       300</span><br><span class="line">CIPHER:     aes128 (4)</span><br><span class="line">MAC:       sha256 (5)</span><br><span class="line">ZIP:       none (0)</span><br><span class="line">UID:       root (0)</span><br><span class="line">GID:       root (0)</span><br><span class="line">LENGTH:     0</span><br><span class="line">[root@admin ~]<span class="comment"># munge -n | ssh node2 unmunge</span></span><br></pre></td></tr></table></figure>

<h6 id="6、-安装NTP时间服务器（每台都要安装）"><a href="#6、-安装NTP时间服务器（每台都要安装）" class="headerlink" title="6、 安装NTP时间服务器（每台都要安装）"></a>6、 安装NTP时间服务器（每台都要安装）</h6><p>安装配置ntp时间同步</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># yum install ntp ntpdate -y</span></span><br></pre></td></tr></table></figure>

<p>配置ntp</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/ntp.conf</span></span><br><span class="line"><span class="comment"># For more information about this file, see the man pages</span></span><br><span class="line"><span class="comment"># ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).</span></span><br><span class="line">driftfile /var/lib/ntp/drift</span><br><span class="line"><span class="comment">#新增:日志目录.</span></span><br><span class="line">logfile /var/log/ntpd.log</span><br><span class="line"><span class="comment"># Permit time synchronization with our time source, but do not</span></span><br><span class="line"><span class="comment"># permit the source to query or modify the service on this system.</span></span><br><span class="line">restrict default nomodify notrap nopeer noquery</span><br><span class="line"><span class="comment"># Permit all access over the loopback interface. This could</span></span><br><span class="line"><span class="comment"># be tightened as well, but to do so would effect some of</span></span><br><span class="line"><span class="comment"># the administrative functions.</span></span><br><span class="line">restrict 127.0.0.1</span><br><span class="line">restrict ::1</span><br><span class="line"><span class="comment">#这一行的含义是授权172.16.128.0网段上的所有机器可以从这台机器上查询和同步时间.</span></span><br><span class="line">restrict 192.168.111.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line"><span class="comment"># Hosts on local network are less restricted.</span></span><br><span class="line"><span class="comment">#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span></span><br><span class="line"><span class="comment"># Use public servers from the pool.ntp.org project.</span></span><br><span class="line"><span class="comment"># Please consider joining the pool (http://www.pool.ntp.org/join.html).</span></span><br><span class="line"><span class="comment">#server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 3.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#新增:时间服务器列表.</span></span><br><span class="line">server 0.cn.pool.ntp.org iburst</span><br><span class="line">server 1.cn.pool.ntp.org iburst</span><br><span class="line">server 2.cn.pool.ntp.org iburst</span><br><span class="line">server 3.cn.pool.ntp.org iburst</span><br><span class="line"><span class="comment">#新增:当外部时间不可用时，使用本地时间.</span></span><br><span class="line">server 172.16.128.171 iburst</span><br><span class="line">fudge 127.0.0.1 stratum 10</span><br><span class="line"><span class="comment">#broadcast 192.168.1.255 autokey # broadcast server</span></span><br><span class="line"><span class="comment">#broadcastclient # broadcast client</span></span><br><span class="line"><span class="comment">#broadcast 224.0.1.1 autokey # multicast server</span></span><br><span class="line"><span class="comment">#multicastclient 224.0.1.1 # multicast client</span></span><br><span class="line"><span class="comment">#manycastserver 239.255.254.254 # manycast server</span></span><br><span class="line"><span class="comment">#manycastclient 239.255.254.254 autokey # manycast client</span></span><br><span class="line"><span class="comment">#新增:允许上层时间服务器主动修改本机时间.</span></span><br><span class="line">restrict 0.cn.pool.ntp.org nomodify notrap noquery</span><br><span class="line">restrict 1.cn.pool.ntp.org nomodify notrap noquery</span><br><span class="line">restrict 2.cn.pool.ntp.org nomodify notrap noquery</span><br><span class="line"><span class="comment"># Enable public key cryptography.</span></span><br><span class="line"><span class="comment">#crypto</span></span><br><span class="line">includefile /etc/ntp/crypto/pw</span><br><span class="line"><span class="comment"># Key file containing the keys and key identifiers used when operating</span></span><br><span class="line"><span class="comment"># with symmetric key cryptography.</span></span><br><span class="line">keys /etc/ntp/keys</span><br><span class="line"><span class="comment"># Specify the key identifiers which are trusted.</span></span><br><span class="line"><span class="comment">#trustedkey 4 8 42</span></span><br><span class="line"><span class="comment"># Specify the key identifier to use with the ntpdc utility.</span></span><br><span class="line"><span class="comment">#requestkey 8</span></span><br><span class="line"><span class="comment"># Specify the key identifier to use with the ntpq utility.</span></span><br><span class="line"><span class="comment">#adminkey 8</span></span><br><span class="line"><span class="comment"># Enable writing of statistics records.</span></span><br><span class="line"><span class="comment">#statistics clockstats cryptostats loopstats peerstats</span></span><br><span class="line"><span class="comment"># Disable the monitoring facility to prevent amplification attacks using ntpdc</span></span><br><span class="line"><span class="comment"># monlist command when default restrict does not include the noquery flag. See</span></span><br><span class="line"><span class="comment"># CVE-2013-5211 for more details.</span></span><br><span class="line"><span class="comment"># Note: Monitoring will not be disabled with the limited restriction flag.</span></span><br><span class="line"><span class="built_in">disable</span> monitor </span><br></pre></td></tr></table></figure>

<p>启动ntp服务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># systemctl start ntpd</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl enable ntpd</span></span><br></pre></td></tr></table></figure>

<p>查看ntp连接状态如果没有问题，将正确时间写入硬件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># ss -tlunp | grep ntp</span></span><br><span class="line">[root@admin ~]<span class="comment"># ntpq –p</span></span><br><span class="line">[root@admin ~]<span class="comment"># hwclock -w</span></span><br></pre></td></tr></table></figure>

<p>ntp客户端</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># cat /etc/ntp.conf</span></span><br><span class="line">server 192.168.111.128     <span class="comment">#修改server后为admin管理节点IP地址</span></span><br></pre></td></tr></table></figure>

<p>重要：修改任意节点服务器的NTP配置文件都需要重起ntpd服务：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># systemctl restart ntpd</span></span><br><span class="line">[root@node1 ~]<span class="comment"># systemctl status ntpd</span></span><br></pre></td></tr></table></figure>

<p>以crontab任务计划同步时间（需安装ntpdate，每天24点更新同步时间）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># crontab -e</span></span><br><span class="line">0 0 * * * /usr/sbin/sntp -P no -r 192.168.111.128;hwclock -w</span><br></pre></td></tr></table></figure>

<h6 id="7、-安装MySQL8"><a href="#7、-安装MySQL8" class="headerlink" title="7、 安装MySQL8"></a>7、 安装MySQL8</h6><p>推荐使用rpm安装包方便管理</p>
<p>下载地址<a target="_blank" rel="noopener" href="https://dev.mysql.com/downloads/">https://dev.mysql.com/downloads/</a></p>
<p>配置MySQL Yum Repository方式安装（需要服务器联网）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@admin sourcecode]<span class="comment"># wget https://repo.mysql.com//mysql80-community-release-el7-6.noarch.rpm</span></span><br><span class="line">[root@admin sourcecode]<span class="comment"># rpm -ivh mysql80-community-release-el7-6.noarch.rpm</span></span><br><span class="line">[root@admin sourcecode]<span class="comment"># yum clean all</span></span><br><span class="line">[root@admin sourcecode]<span class="comment"># yum repolist</span></span><br><span class="line">[root@admin ~]<span class="comment"># yum install mysql-community-&#123;server,client,common,libs,devel&#125;-*</span></span><br><span class="line">Package mysql-community-server-8.0.30-1.el7.x86_64 already installed and latest version</span><br><span class="line">Package mysql-community-server-debug-8.0.30-1.el7.x86_64 already installed and latest version</span><br><span class="line">Package mysql-community-client-plugins-8.0.30-1.el7.x86_64 already installed and latest version</span><br><span class="line">Package mysql-community-client-8.0.30-1.el7.x86_64 already installed and latest version</span><br><span class="line">Package mysql-community-common-8.0.30-1.el7.x86_64 already installed and latest version</span><br><span class="line">Package mysql-community-libs-8.0.30-1.el7.x86_64 already installed and latest version</span><br><span class="line">Package mysql-community-libs-compat-8.0.30-1.el7.x86_64 already installed and latest version</span><br><span class="line">Package mysql-community-devel-8.0.30-1.el7.x86_64 already installed and latest version</span><br><span class="line">Nothing to <span class="keyword">do</span></span><br></pre></td></tr></table></figure>

<p>注意：要安装mysql-community-devel工具，否则slurm会报错找不到accounting_storage_mysql.so</p>
<p>下载离线安装包，解压，cd到目录</p>
<p><a target="_blank" rel="noopener" href="https://downloads.mysql.com/archives/community/">https://downloads.mysql.com/archives/community/</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@admin sourcecode]<span class="comment"># wget https://cdn.mysql.com/archives/mysql-8.0/mysql-8.0.29-el7-x86_64.tar.gz</span></span><br><span class="line">[root@admin ~]<span class="comment"># yum localinstall mysql-community-&#123;server,client,common,libs,devel&#125;-*</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl start mysqld</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl enable mysqld</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl status mysqld</span></span><br><span class="line">● mysqld.service - MySQL Server</span><br><span class="line">  Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled)</span><br><span class="line">  Active: active (running)</span><br></pre></td></tr></table></figure>

<p>MySQL8.0安装之后查找默认密码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># grep &#x27;temporary password&#x27; /var/log/mysqld.log</span></span><br><span class="line">[root@admin ~]<span class="comment"># mysql -u root -p</span></span><br><span class="line">Enter password:</span><br></pre></td></tr></table></figure>

<p>设置新密码</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> use mysql;</span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">ALTER</span> <span class="keyword">USER</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> IDENTIFIED <span class="keyword">WITH</span> mysql_native_password <span class="keyword">BY</span> <span class="string">&#x27;Inspur1!&#x27;</span>;</span><br><span class="line">mysql<span class="operator">&gt;</span> flush privileges;</span><br><span class="line">mysql<span class="operator">&gt;</span> exit</span><br><span class="line">Bye</span><br><span class="line">[root<span class="variable">@admin</span> <span class="operator">~</span>]# mysql <span class="operator">-</span>u root <span class="operator">-</span>p<span class="string">&#x27;Inspur1!&#x27;</span></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br></pre></td></tr></table></figure>

<p>生成slurm用户，以便该用户操作slurm_acct_db数据库，其密码是Inspur1！</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">user</span> <span class="string">&#x27;slurm&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> identified <span class="keyword">by</span> <span class="string">&#x27;Inspur1！&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>生成账户数据库slurm_acct_db</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create</span> database slurm_acct_db;</span><br></pre></td></tr></table></figure>

<p>赋予slurm从本机localhost采用密码Inspur1！登录具备操作slurm_acct_db数据下所有表的全部权限</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> slurm_acct_db.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;slurm&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> <span class="keyword">with</span> <span class="keyword">grant</span> option;</span><br></pre></td></tr></table></figure>

<p>生成作业信息数据库slurm_jobcomp_db</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create</span> database slurm_jobcomp_db;</span><br></pre></td></tr></table></figure>

<p>赋予slurm从本机localhost采用密码Inspur1！登录具备操作slurm_jobcomp_db数据下所有表的全部权限</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">grant</span> <span class="keyword">all</span> <span class="keyword">on</span> slurm_jobcomp_db.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;slurm&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> <span class="keyword">with</span> <span class="keyword">grant</span> option;</span><br></pre></td></tr></table></figure>

<h6 id="8、-安装slurm"><a href="#8、-安装slurm" class="headerlink" title="8、 安装slurm"></a>8、 安装slurm</h6><p>前提：</p>
<p>时间同步（ntp），创建slurm用户，用户id和用户组id在各个计算节点一致；安装了munge</p>
<p>在控制器和每个节点创建同一个用户slurm</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># id slurm</span></span><br><span class="line">uid=412(slurm) gid=412(slurm) <span class="built_in">groups</span>=412(slurm)</span><br></pre></td></tr></table></figure>

<p>slurm下载地址</p>
<p><a target="_blank" rel="noopener" href="https://www.schedmd.com/downloads.php">https://www.schedmd.com/downloads.php</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin sourcecode]<span class="comment"># wget https://download.schedmd.com/slurm/slurm-22.05.2.tar.bz2</span></span><br></pre></td></tr></table></figure>

<p>安装cgroup插件</p>
<p>在构建rpm前安装好hwloc,在安装slurm后需要配置cgroup.conf</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install hwloc</span><br></pre></td></tr></table></figure>

<p>构建slurm rpm安装包</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpmbuild -ta slurm*.tar.bz2</span><br><span class="line">[root@admin sourcecode]<span class="comment"># rpmbuild -ta slurm-22.05.2.tar.bz2</span></span><br></pre></td></tr></table></figure>

<p>构建是可能会提示需要安装某个依赖，安装依赖后重新构建</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum -y install python3 readline-devel perl pam-devel</span><br><span class="line">yum -y install perl*</span><br><span class="line">rpmbuild -ta slurm*.tar.bz2</span><br></pre></td></tr></table></figure>

<p>生成的rpm包目录，安装所有slurm rpm包</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@admin sourcecode]<span class="comment"># cd /root/rpmbuild/RPMS/x86_64/</span></span><br><span class="line">yum install slurm*</span><br></pre></td></tr></table></figure>

<p>配置好后将slurm.conf 复制到计算节点，常规位置在:/etc/slurm/</p>
<p>[root@admin ~]# cat /etc/slurm/slurm.conf</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Cluster Name：集群名</span></span><br><span class="line">ClusterName=hpccluster <span class="comment"># 集群名，任意英文和数字名字</span></span><br><span class="line"><span class="comment"># Control Machines：Slurmctld控制进程节点</span></span><br><span class="line">SlurmctldHost=admin <span class="comment"># 启动slurmctld进程的节点名，如这里的admin</span></span><br><span class="line"><span class="comment">#BackupController=  # 冗余备份节点，可空着</span></span><br><span class="line">SlurmctldParameters=enable_configless <span class="comment"># 采用无配置模式</span></span><br><span class="line"><span class="comment"># Slurm User：Slurm用户</span></span><br><span class="line">SlurmUser=slurm   <span class="comment"># slurmctld启动时采用的用户名</span></span><br><span class="line"><span class="comment"># Slurm Port Numbers：Slurm服务通信端口</span></span><br><span class="line">SlurmctldPort=6817 <span class="comment"># Slurmctld服务端口，设为6817，如不设置，默认为6817号端口</span></span><br><span class="line">SlurmdPort=6818  <span class="comment"># Slurmd服务端口，设为6818，如不设置，默认为6818号端口</span></span><br><span class="line"><span class="comment"># State Preservation：状态保持</span></span><br><span class="line">StateSaveLocation=/var/spool/slurmctld <span class="comment"># 存储slurmctld服务状态的目录，如有备份控制节点，则需要所有SlurmctldHost节点都能共享读写该目录</span></span><br><span class="line">SlurmdSpoolDir=/var/spool/slurmd <span class="comment"># Slurmd服务所需要的目录，为各节点各自私有目录，不得多个slurmd节点共享</span></span><br><span class="line">ReturnToService=1 <span class="comment">#设定当DOWN（失去响应）状态节点如何恢复服务，默认为0。</span></span><br><span class="line"><span class="comment"># 0: 节点状态保持DOWN状态，只有当管理员明确使其恢复服务时才恢复</span></span><br><span class="line"><span class="comment"># 1: 仅当由于无响应而将DOWN节点设置为DOWN状态时，才可以当有效配置注册后使DOWN节点恢复服务。如节点由于任何其它原因（内存不足、意外重启等）被设置为DOWN，其状态将不会自动更改。当节点的内存、GRES、CPU计数等等于或大于slurm.conf中配置的值时，该节点才注册为有效配置。</span></span><br><span class="line"><span class="comment"># 2: 使用有效配置注册后，DOWN节点将可供使用。该节点可能因任何原因被设置为DOWN状态。当节点的内存、GRES、CPU计数等等于或大于slurm.conf 中配置的值，该节点才注册为有效配置。￼</span></span><br><span class="line"><span class="comment"># Default MPI Type：默认MPI类型</span></span><br><span class="line">MPIDefault=None</span><br><span class="line">  <span class="comment"># MPI-PMI2: 对支持PMI2的MPI实现</span></span><br><span class="line">  <span class="comment"># MPI-PMIx: Exascale PMI实现</span></span><br><span class="line">  <span class="comment"># None: 对于大多数其它MPI，建议设置</span></span><br><span class="line"><span class="comment"># Process Tracking：进程追踪，定义用于确定特定的作业所对应的进程的算法，它使用信号、杀死和记账与作业步相关联的进程</span></span><br><span class="line">ProctrackType=proctrack/cgroup</span><br><span class="line">  <span class="comment"># Cgroup: 采用Linux cgroup来生成作业容器并追踪进程，需要设定/etc/slurm/cgroup.conf文件</span></span><br><span class="line">  <span class="comment"># Cray XC: 采用Cray XC专有进程追踪</span></span><br><span class="line">  <span class="comment"># LinuxProc: 采用父进程IP记录，进程可以脱离Slurm控制</span></span><br><span class="line">  <span class="comment"># Pgid: 采用Unix进程组ID(Process Group ID)，进程如改变了其进程组ID则可以脱离Slurm控制</span></span><br><span class="line"><span class="comment"># Scheduling：调度</span></span><br><span class="line"><span class="comment"># DefMemPerCPU=0 # 默认每颗CPU可用内存，以MB为单位，0为不限制。如果将单个处理器分配给作业（SelectType=select/cons_res 或 SelectType=select/cons_tres），通常会使用DefMemPerCPU</span></span><br><span class="line"><span class="comment"># MaxMemPerCPU=0 # 最大每颗CPU可用内存，以MB为单位，0为不限制。如果将单个处理器分配给作业（SelectType=select/cons_res 或 SelectType=select/cons_tres），通常会使用MaxMemPerCPU</span></span><br><span class="line"><span class="comment"># SchedulerTimeSlice=30 # 当GANG调度启用时的时间片长度，以秒为单位</span></span><br><span class="line">SchedulerType=<span class="built_in">sched</span>/backfill <span class="comment"># 要使用的调度程序的类型。注意，slurmctld守护程序必须重新启动才能使调度程序类型的更改生效（重新配置正在运行的守护程序对此参数无效）。如果需要，可以使用scontrol命令手动更改作业优先级。可接受的类型为：</span></span><br><span class="line">  <span class="comment"># sched/backfill # 用于回填调度模块以增加默认FIFO调度。如这样做不会延迟任何较高优先级作业的预期启动时间，则回填调度将启动较低优先级作业。回填调度的有效性取决于用户指定的作业时间限制，否则所有作业将具有相同的时间限制，并且回填是不可能的。注意上面SchedulerParameters选项的文档。这是默认配置</span></span><br><span class="line">  <span class="comment"># sched/builtin # 按优先级顺序启动作业的FIFO调度程序。如队列中的任何作业无法调度，则不会调度该队列中优先级较低的作业。对于作业的一个例外是由于队列限制（如时间限制）或关闭/耗尽节点而无法运行。在这种情况下，可以启动较低优先级的作业，而不会影响较高优先级的作业。</span></span><br><span class="line">  <span class="comment"># sched/hold # 如果 /etc/slurm.hold 文件存在，则暂停所有新提交的作业，否则使用内置的FIFO调度程序。</span></span><br><span class="line"><span class="comment"># Resource Selection：资源选择，定义作业资源（节点）选择算法</span></span><br><span class="line">SelectType=select/cons_tres</span><br><span class="line">  <span class="comment"># select/cons_tres: 单个的CPU核、内存、GPU及其它可追踪资源作为可消费资源（消费及分配），建议设置</span></span><br><span class="line">  <span class="comment"># select/cons_res: 单个的CPU核和内存作为可消费资源</span></span><br><span class="line">  <span class="comment"># select/cray_aries: 对于Cray系统</span></span><br><span class="line">  <span class="comment"># select/linear: 基于主机的作为可消费资源，不管理单个CPU等的分配</span></span><br><span class="line"><span class="comment"># SelectTypeParameters：资源选择类型参数，当SelectType=select/linear时仅支持CR_ONE_TASK_PER_CORE和CR_Memory；当SelectType=select/cons_res、SelectType=select/cray_aries和SelectType=select/cons_tres时，默认采用CR_Core_Memory</span></span><br><span class="line">SelectTypeParameters=CR_Core_Memory</span><br><span class="line">  <span class="comment"># CR_CPU: CPU核数作为可消费资源</span></span><br><span class="line">  <span class="comment"># CR_Socket: 整颗CPU作为可消费资源</span></span><br><span class="line">  <span class="comment"># CR_Core: CPU核作为可消费资源，默认</span></span><br><span class="line">  <span class="comment"># CR_Memory: 内存作为可消费资源，CR_Memory假定MaxShare大于等于1</span></span><br><span class="line">  <span class="comment"># CR_CPU_Memory: CPU和内存作为可消费资源</span></span><br><span class="line">  <span class="comment"># CR_Socket_Memory: 整颗CPU和内存作为可消费资源</span></span><br><span class="line">  <span class="comment"># CR_Core_Memory: CPU和和内存作为可消费资源</span></span><br><span class="line"><span class="comment"># Task Launch：任务启动</span></span><br><span class="line">TaskPlugin=task/cgroup,task/affinity <span class="comment">#设定任务启动插件。可被用于提供节点内的资源管理（如绑定任务到特定处理器），TaskPlugin值可为:</span></span><br><span class="line">  <span class="comment"># task/affinity: CPU亲和支持（man srun查看其中--cpu-bind、--mem-bind和-E选项）</span></span><br><span class="line">  <span class="comment"># task/cgroup: 强制采用Linux控制组cgroup分配资源（man group.conf查看帮助）</span></span><br><span class="line">  <span class="comment"># task/none: #无任务启动动作</span></span><br><span class="line"><span class="comment"># Prolog and Epilog：前处理及后处理</span></span><br><span class="line"><span class="comment"># Prolog/Epilog: 完整的绝对路径，在用户作业开始前(Prolog)或结束后(Epilog)在其每个运行节点上都采用root用户执行，可用于初始化某些参数、清理作业运行后的可删除文件等</span></span><br><span class="line"><span class="comment"># Prolog=/opt/bin/prolog.sh # 作业开始运行前需要执行的文件，采用root用户执行</span></span><br><span class="line"><span class="comment"># Epilog=/opt/bin/epilog.sh # 作业结束运行后需要执行的文件，采用root用户执行</span></span><br><span class="line"><span class="comment"># SrunProlog/Epilog # 完整的绝对路径，在用户作业步开始前(SrunProlog)或结束后(Epilog)在其每个运行节点上都被srun执行，这些参数可以被srun的--prolog和--epilog选项覆盖</span></span><br><span class="line"><span class="comment"># SrunProlog=/opt/bin/srunprolog.sh # 在srun作业开始运行前需要执行的文件，采用运行srun命令的用户执行</span></span><br><span class="line"><span class="comment"># SrunEpilog=/opt/bin/srunepilog.sh # 在srun作业结束运行后需要执行的文件，采用运行srun命令的用户执行</span></span><br><span class="line"><span class="comment"># TaskProlog/Epilog: 绝对路径，在用户任务开始前(Prolog)和结束后(Epilog)在其每个运行节点上都采用运行作业的用户身份执行</span></span><br><span class="line"><span class="comment"># TaskProlog=/opt/bin/taskprolog.sh # 作业开始运行前需要执行的文件，采用运行作业的用户执行</span></span><br><span class="line"><span class="comment"># TaskEpilog=/opt/bin/taskepilog.sh # 作业结束后需要执行的文件，采用运行作业的用户执行行</span></span><br><span class="line"><span class="comment"># 顺序：</span></span><br><span class="line">  <span class="comment"># 1. pre_launch_priv()：TaskPlugin内部函数</span></span><br><span class="line">  <span class="comment"># 2. pre_launch()：TaskPlugin内部函数</span></span><br><span class="line">  <span class="comment"># 3. TaskProlog：slurm.conf中定义的系统范围每个任务</span></span><br><span class="line">  <span class="comment"># 4. User prolog：作业步指定的，采用srun命令的--task-prolog参数或SLURM_TASK_PROLOG环境变量指定</span></span><br><span class="line">  <span class="comment"># 5. Task：作业步任务中执行</span></span><br><span class="line">  <span class="comment"># 6. User epilog：作业步指定的，采用srun命令的--task-epilog参数或SLURM_TASK_EPILOG环境变量指定</span></span><br><span class="line">  <span class="comment"># 7. TaskEpilog：slurm.conf中定义的系统范围每个任务</span></span><br><span class="line">  <span class="comment"># 8. post_term()：TaskPlugin内部函数</span></span><br><span class="line"><span class="comment"># Event Logging：事件记录</span></span><br><span class="line"><span class="comment"># Slurmctld和slurmd守护进程可以配置为采用不同级别的详细度记录，从0（不记录）到7（极度详细）</span></span><br><span class="line">SlurmctldDebug=info <span class="comment"># 默认为info</span></span><br><span class="line">SlurmctldLogFile=/var/log/slurm/slurmctld.log <span class="comment"># 如是空白，则记录到syslog</span></span><br><span class="line">SlurmdDebug=info <span class="comment"># 默认为info</span></span><br><span class="line">SlurmdLogFile=/var/log/slurm/slurmd.log <span class="comment"># 如为空白，则记录到syslog，如名字中的有字符串&quot;%h&quot;，则&quot;%h&quot;将被替换为节点名</span></span><br><span class="line"><span class="comment"># Job Completion Logging：作业完成记录</span></span><br><span class="line">JobCompType=jobcomp/mysql</span><br><span class="line"><span class="comment"># 指定作业完成是采用的记录机制，默认为None，可为以下值之一:</span></span><br><span class="line">  <span class="comment"># None: 不记录作业完成信息</span></span><br><span class="line">  <span class="comment"># Elasticsearch: 将作业完成信息记录到Elasticsearch服务器</span></span><br><span class="line">  <span class="comment"># FileTxt: 将作业完成信息记录在一个纯文本文件中</span></span><br><span class="line">  <span class="comment"># Lua: 利用名为jobcomp.lua的文件记录作业完成信息</span></span><br><span class="line">  <span class="comment"># Script: 采用任意脚本对原始作业完成信息进行处理后记录</span></span><br><span class="line">  <span class="comment"># MySQL: 将完成状态写入MySQL或MariaDB数据库</span></span><br><span class="line"><span class="comment"># JobCompLoc= # 设定记录作业完成信息的文本文件位置（若JobCompType=filetxt），或将要运行的脚本（若JobCompType=script），或Elasticsearch服务器的URL（若JobCompType=elasticsearch），或数据库名字（JobCompType为其它值时） </span></span><br><span class="line"><span class="comment"># 设定数据库在哪里运行，且如何连接</span></span><br><span class="line">JobCompHost=localhost <span class="comment"># 存储作业完成信息的数据库主机名</span></span><br><span class="line">JobCompPort=3036    <span class="comment"># 存储作业完成信息的数据库服务器监听端口</span></span><br><span class="line">JobCompUser=slurm   <span class="comment"># 用于与存储作业完成信息数据库进行对话的用户名</span></span><br><span class="line">JobCompPass=Inspur1! <span class="comment"># 用于与存储作业完成信息数据库进行对话的用户密码</span></span><br><span class="line"><span class="comment"># Job Accounting Gather：作业记账收集</span></span><br><span class="line">JobAcctGatherType=jobacct_gather/linux <span class="comment"># Slurm记录每个作业消耗的资源，JobAcctGatherType值可为以下之一：</span></span><br><span class="line">  <span class="comment"># jobacct_gather/none: 不对作业记账</span></span><br><span class="line">  <span class="comment"># jobacct_gather/cgroup: 收集Linux cgroup信息</span></span><br><span class="line">  <span class="comment"># jobacct_gather/linux: 收集Linux进程表信息，建议</span></span><br><span class="line">JobAcctGatherFrequency=30 <span class="comment"># 设定轮寻间隔，以秒为单位。若为-，则禁止周期性抽样</span></span><br><span class="line">  <span class="comment"># Job Accounting Storage：作业记账存储</span></span><br><span class="line">AccountingStorageType=accounting_storage/slurmdbd <span class="comment"># 与作业记账收集一起，Slurm可以采用不同风格存储可以以许多不同的方式存储会计信息，可为以下值之一：</span></span><br><span class="line">  <span class="comment"># accounting_storage/none: 不记录记账信息</span></span><br><span class="line">  <span class="comment"># accounting_storage/slurmdbd: 将作业记账信息写入Slurm DBD数据库</span></span><br><span class="line">  <span class="comment"># AccountingStorageLoc: 设定文件位置或数据库名，为完整绝对路径或为数据库的数据库名，当采用slurmdb时默认为slurm_acct_db</span></span><br><span class="line"><span class="comment"># 设定记账数据库信息，及如何连接</span></span><br><span class="line">AccountingStorageHost=localhost <span class="comment"># 记账数据库主机名</span></span><br><span class="line"><span class="comment"># AccountingStoragePort= # 记账数据库服务监听端口</span></span><br><span class="line"><span class="comment"># AccountingStorageUser=slurm # 记账数据库用户名</span></span><br><span class="line"><span class="comment"># AccountingStoragePass=SomePassWD # 记账数据库用户密码。对于SlurmDBD，提供企业范围的身份验证，如采用于Munge守护进程，则这是应该用munge套接字socket名（/var/run/munge/global.socket.2）代替。默认不设置</span></span><br><span class="line"><span class="comment"># AccountingStoreFlags= # 以逗号（,）分割的列表。选项是：</span></span><br><span class="line">  <span class="comment"># job_comment：在数据库中存储作业说明域</span></span><br><span class="line">  <span class="comment"># job_script：在数据库中存储脚本</span></span><br><span class="line">  <span class="comment"># job_env：存储批处理作业的环境变量</span></span><br><span class="line"><span class="comment"># AccountingStorageTRES=gres/gpu # 设置GPU时需要</span></span><br><span class="line"><span class="comment"># GresTypes=gpu # 设置GPU时需要</span></span><br><span class="line"><span class="comment"># Process ID Logging：进程ID记录，定义记录守护进程的进程ID的位置</span></span><br><span class="line">SlurmctldPidFile=/var/run/slurmctld.pid <span class="comment"># 存储slurmctld进程号PID的文件</span></span><br><span class="line">SlurmdPidFile=/var/run/slurmd.pid <span class="comment"># 存储slurmd进程号PID的文件</span></span><br><span class="line"><span class="comment"># Timers：定时器</span></span><br><span class="line">SlurmctldTimeout=120 <span class="comment"># 设定备份控制器在主控制器等待多少秒后成为激活的控制器</span></span><br><span class="line">SlurmdTimeout=300 <span class="comment"># Slurm控制器等待slurmd未响应请求多少秒后将该节点状态设置为DOWN</span></span><br><span class="line">InactiveLimit=0 <span class="comment"># 潜伏期控制器等待srun命令响应多少秒后，将在考虑作业或作业步骤不活动并终止它之前。0表示无限长等待</span></span><br><span class="line">MinJobAge=300 <span class="comment"># Slurm控制器在等待作业结束多少秒后清理其记录</span></span><br><span class="line">KillWait=30 <span class="comment"># 在作业到达其时间限制前等待多少秒后在发送SIGKILLL信号之前发送TERM信号以优雅地终止</span></span><br><span class="line">WaitTime=0 <span class="comment"># 在一个作业步的第一个任务结束后等待多少秒后结束所有其它任务，0表示无限长等待</span></span><br><span class="line"><span class="comment"># Compute Machines：计算节点</span></span><br><span class="line"><span class="comment"># NodeName=node[1-10] NodeAddr=192.168.1.[1-8] CPUs=48 RealMemory=192000 Sockets=2 CoresPerSocket=24 ThreadsPerCore=1 State=UNKNOWN</span></span><br><span class="line">NodeName=admin   CPUs=2 Boards=1 SocketsPerBoard=2 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=1000</span><br><span class="line">NodeName=node[1-2] CPUs=2 Boards=1 SocketsPerBoard=2 CoresPerSocket=1 ThreadsPerCore=1 RealMemory=1000</span><br><span class="line"><span class="comment"># NodeName=gnode[01-10] Gres=gpu:v100:2 CPUs=40 RealMemory=385560 Sockets=2 CoresPerSocket=20 ThreadsPerCore=1 State=UNKNOWN #GPU节点例子，主要为Gres=gpu:v100:2</span></span><br><span class="line">  <span class="comment"># NodeName=node[1-10] # 计算节点名，node[1-10]表示为从node1、node2连续编号到node10，其余类似</span></span><br><span class="line">  <span class="comment"># NodeAddr=192.168.1.[1-10] # 计算节点IP</span></span><br><span class="line">  <span class="comment"># CPUs=48 # 节点内CPU核数，如开着超线程，则按照2倍核数计算，其值为：Sockets*CoresPerSocket*ThreadsPerCore</span></span><br><span class="line">  <span class="comment"># RealMemory=192000 # 节点内作业可用内存数(MB)，一般不大于free -m的输出，当启用select/cons_res插件限制内存时使用</span></span><br><span class="line">  <span class="comment"># Sockets=2 # 节点内CPU颗数</span></span><br><span class="line">  <span class="comment"># CoresPerSocket=24 # 每颗CPU核数</span></span><br><span class="line">  <span class="comment"># ThreadsPerCore=1 # 每核逻辑线程数，如开了超线程，则为2</span></span><br><span class="line">  <span class="comment"># State=UNKNOWN # 状态，是否启用，State可以为以下之一：</span></span><br><span class="line">    <span class="comment"># CLOUD  # 在云上存在</span></span><br><span class="line">    <span class="comment"># DOWN  # 节点失效，不能分配给在作业</span></span><br><span class="line">    <span class="comment"># DRAIN  # 节点不能分配给作业</span></span><br><span class="line">    <span class="comment"># FAIL  # 节点即将失效，不能接受分配新作业</span></span><br><span class="line">    <span class="comment"># FAILING # 节点即将失效，但上面有作业未完成，不能接收新作业</span></span><br><span class="line">    <span class="comment"># FUTURE # 节点为了将来使用，当Slurm守护进程启动时设置为不存在，可以之后采用scontrol命令简单地改变其状态，而不是需要重启slurmctld守护进程。当这些节点有效后，修改slurm.conf中它们的State。在它们被设置为有效前，采用Slurm看不到它们，也尝试与其联系。</span></span><br><span class="line">    <span class="comment"># 动态未来节点(Dynamic Future Nodes)：</span></span><br><span class="line">    <span class="comment"># slurmd启动时如有-F[&lt;feature&gt;]参数，将关联到一个与slurmd -C命令显示配置(sockets、cores、threads)相同的配置的FUTURE节点。节点的NodeAddr和NodeHostname从slurmd守护进程自动获取，并且当被设置为FUTURE状态后自动清除。动态未来节点在重启时保持non-FUTURE状态。利用scontrol可以将其设置为FUTURE状态。</span></span><br><span class="line">    <span class="comment"># 若NodeName与slurmd的HostName映射未通过DNS更新，动态未来节点不知道在之间如何进行通信，其原因在于NodeAddr和NodeHostName未在slurm.conf被定义，而且扇出通信(fanout communication)需要通过将TreeWidth设置为一个较高的数字（如65533）来使其无效。若做了DNS映射，则可以使用cloud_dns SlurmctldParameter。</span></span><br><span class="line">     <span class="comment"># UNKNOWN # 节点状态未被定义，但将在节点上启动slurmd进程后设置为BUSY或IDLE，该为默认值。</span></span><br><span class="line">PartitionName=hpc Nodes=node[1-2],admin Default=YES MaxTime=INFINITE State=UP</span><br><span class="line">  <span class="comment"># PartitionName=batch # 队列分区名</span></span><br><span class="line">  <span class="comment"># Nodes=node[1-10] # 节点名</span></span><br><span class="line">  <span class="comment"># Default=Yes # 作为默认队列，运行作业不知明队列名时采用的队列</span></span><br><span class="line">  <span class="comment"># MaxTime=INFINITE # 作业最大运行时间，以分钟为单位，INFINITE表示为无限制</span></span><br><span class="line">  <span class="comment"># State=UP # 状态，是否启用</span></span><br><span class="line">  <span class="comment"># Gres=gpu:v100:2 # 设置节点有两块v100 GPU卡，需要在GPU节点 /etc/slum/gres.conf 文件中有类似下面配置：</span></span><br><span class="line">  <span class="comment"># AutoDetect=nvml Name=gpu Type=v100 File=/dev/nvidia[0-1] #设置资源的名称Name是gpu，类型Type为v100，名称与类型可以任意取，但需要与其它方面配置对应，File=/dev/nvidia[0-1]指明了使用的GPU设备。</span></span><br><span class="line">  <span class="comment"># Name=mps Count=100</span></span><br><span class="line">[root@admin ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p>[root@admin ~]# cat /etc/slurm/slurmdbd.conf</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 认证信息</span></span><br><span class="line">AuthType=auth/munge <span class="comment"># 认证方式，该处采用munge进行认证</span></span><br><span class="line">AuthInfo=/var/run/munge/munge.socket.2 <span class="comment"># 为了与slurmctld控制节点通信的其它认证信息</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># slurmDBD信息</span></span><br><span class="line">DbdHost=localhost <span class="comment"># 数据库节点名</span></span><br><span class="line">DbdAddr=127.0.0.1 <span class="comment"># 数据库IP地址</span></span><br><span class="line"><span class="comment"># DbdBackupHost=admin2 # 数据库冗余备份节点</span></span><br><span class="line"><span class="comment"># DbdPort=7031 # 数据库端口号，默认为7031</span></span><br><span class="line">SlurmUser=slurm <span class="comment"># 用户数据库操作的用户</span></span><br><span class="line">MessageTimeout=60 <span class="comment"># 允许以秒为单位完成往返通信的时间，默认为10秒 </span></span><br><span class="line">DebugLevel=debug5 <span class="comment"># 调试信息级别，quiet：无调试信息；fatal：仅严重错误信息；error：仅错误信息； info：错误与通常信息；verbose：错误和详细信息；debug：错误、详细和调试信息；debug2：错误、详细和更多调试信息；debug3：错误、详细和甚至更多调试信息；debug4：错误、详细和甚至更多调试信息；debug5：错误、详细和甚至更多调试信息。debug数字越大，信息越详细</span></span><br><span class="line">DefaultQOS=normal <span class="comment"># 默认QOS</span></span><br><span class="line">LogFile=/var/log/slurm/slurmdbd.log <span class="comment"># slurmdbd守护进程日志文件绝对路径</span></span><br><span class="line">PidFile=/var/run/slurmdbd.pid <span class="comment"># slurmdbd守护进程存储进程号文件绝对路径</span></span><br><span class="line"><span class="comment"># PrivateData=accounts,users,usage,jobs # 对于普通用户隐藏的数据。默认所有信息对所有用户开放，SlurmUser、root和AdminLevel=Admin用户可以查看所有信息。多个值可以采用逗号（,）分割：</span></span><br><span class="line">  <span class="comment"># accounts：阻止用户查看账户信息，除非该用户是他们的协调人</span></span><br><span class="line">  <span class="comment"># events：阻止用户查看事件信息，除非该用户具有操作员或更高级身份</span></span><br><span class="line">  <span class="comment"># jobs：阻止普户查看其他用户的作业信息，除非该用户是使用 sacct 时运行作业的帐户的协调员。</span></span><br><span class="line">  <span class="comment"># reservations：限制具有操作员及以上身份的用户获取资源预留信息。￼</span></span><br><span class="line">  <span class="comment"># usage：阻止用户查看其他用户利用率。适用于sreport命令</span></span><br><span class="line">  <span class="comment"># users：阻止用户查看除自己以外的任何用户的信息，使得用户只能看到他们处理的关联。协调人可以看到他们作为协调人的帐户中所有用户的关联，但只有在列出用户时才能看到自己。</span></span><br><span class="line"><span class="comment">#TrackWCKey=yes # 工作负载特征键。用于设置Workload Characterization Key的显示和跟踪。必须设置为跟踪wckey的使用。这必须设置为从WCKeys生成汇总使用表。注意：如果在此处设置TrackWCKey而不是在您的各种slurm.conf文件中，则所有作业都将归因于它们的默认WCKey。</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Database信息，详细解释参见前面slurm.conf中的</span></span><br><span class="line">StorageType=accounting_storage/mysql <span class="comment"># 数据存储类型</span></span><br><span class="line">StorageHost=localhost <span class="comment"># 存储数据库节点名</span></span><br><span class="line">StorageLoc=slurm_acct_db <span class="comment"># 存储位置</span></span><br><span class="line">StoragePort=3306 <span class="comment"># 存储数据库服务端口号</span></span><br><span class="line">StorageUser=slurm <span class="comment"># 存储数据库用户名</span></span><br><span class="line">StoragePass=Inspur1! <span class="comment"># 存储数据库密码</span></span><br><span class="line">[root@admin ~]<span class="comment"># </span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># cat /etc/slurm/cgroup.conf</span></span><br><span class="line"><span class="comment">###</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Slurm cgroup support configuration file</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># See man slurm.conf and man cgroup.conf for further</span></span><br><span class="line"><span class="comment"># information on cgroup configuration parameters</span></span><br><span class="line"><span class="comment">#--</span></span><br><span class="line">CgroupAutomount=<span class="built_in">yes</span> <span class="comment"># Cgroup自动挂载。Slurm cgroup插件需要挂载有效且功能正常的cgroup子系统于 /sys/fs/cgroup/&lt;subsystem_name&gt;。当启动时，插件检查该子系统是否可用。如不可用，该插件将启动失败，直到CgroupAutomount设置为yes。在此情形侠，插件首先尝试挂载所需的子系统。</span></span><br><span class="line">CgroupMountpoint=/sys/fs/cgroup <span class="comment"># 设置cgroup挂载点，该目录应该是可写的，可以含有每个子系统挂载的cgroups。默认在/sys/fs/cgroup。</span></span><br><span class="line"><span class="comment"># CgroupPlugin= # 设置与cgroup子系统交互采用的插件。其值可以为cgroup/v1（支持传统的cgroup v1接口）或autodetect（根据系统提供的cgroup版本自动选择）。默认为autodetect。</span></span><br><span class="line">ConstrainCores=<span class="built_in">yes</span> <span class="comment"># 如设为yes，则容器允许将CPU核作为可分配资源子集，该项功能使用cpuset子系统。由于HWLOC 1.11.5版本中修复的错误，除了task/cgroup外，可能还需要task/affinity插件才能正常运行。默认为no。</span></span><br><span class="line">ConstrainDevices=<span class="built_in">yes</span> <span class="comment"># 如设为yes，则容器允许将基于GRES的设备作为可分配资源，这使用设备子系统。默认为no。</span></span><br><span class="line">ConstrainRAMSpace=<span class="built_in">yes</span> <span class="comment"># 如设为yes，则通过将内存软限制设置为分配的内存，并将硬限制设置为分配的内存AllowedRAMSpace来限制作业的内存使用。默认值为no，在这种情况下，如ConstrainSwapSpace设为“yes”，则作业的内存限制将设置为其交换空间(SWAP)限制。</span></span><br><span class="line"><span class="comment">#注意：在使用ConstrainRAMSpace时，如果一个作业步中所有进程使用的总内存大于限制，那么内核将触发内存不足(Out Of Memory，OOM)事件，将杀死作业步中的一个或多个进程。作业步状态将被标记为OOM，但作业步本身将继续运行，作业步中的其它进程也可能继续运行。这与OverMemoryKill的行为不同，后者将终止/取消整个作业步。不同之处还在于，JobAcctGather轮询系统在每个进程的基础上检查内存使用情况。</span></span><br><span class="line"><span class="comment"># MaxRAMPercent=98 #运行作业使用的最大内存百分比。将应用于Slurm未显式分配内存的作业的内存约束（如，Slurm的选择插件未配置为管理内存分配）。该百分比可能是一个任意的浮点数。默认值为100。</span></span><br><span class="line"><span class="comment"># AllowedRAMSpace=96 #运行作业/作业步使用的最大cgroup内存百分比。所提供的百分比可以用浮点数表示，例如101.5。在分配的内存大小下设置cgroup软内存限制，然后在分配的内存(AllowedRAMSpace/100)处设置作业/作业步硬内存限制。如果作业/作业步超出硬限制，则可能触发内存不足(OOM)事件（包括内存关闭），这些事件将记录到内核日志环缓冲区（Linux中的dmesg）。设置AllowedRAMSpace超过100可能会导致系统内存不足(OOM)事件，因为它允许作业/作业步分配比配置给节点更多的内存。建议减少已配置的节点可用内存，以避免系统内存不足(OOM)事件。将AllowedRAMSpace设置为低于100将导致作业接收的内存少于分配的内存，软内存限制将设置为与硬内存限制相同的值。默认值为100。</span></span><br><span class="line">[root@admin ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<p>设置Slurm文件、目录、权限等：</p>
<p>/etc/slurm/slurmdbd.conf文件所有者须为slurm用户：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chown</span> slurm.slurm /etc/slurm/slurmdbd.conf </span><br></pre></td></tr></table></figure>

<p>/etc/slurm/slurmdbd.conf文件权限须为600：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> 600 /etc/slurm/slurmdbd.conf</span><br></pre></td></tr></table></figure>

<p>/etc/slurm/slurm.conf文件所有者须为root用户：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chown</span> root /etc/slurm/slurm.conf</span><br></pre></td></tr></table></figure>

<p>建立slurmctld服务存储其状态等的目录，由slurm.conf中StateSaveLocation参数定义：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /var/spool/slurmctld</span><br></pre></td></tr></table></figure>

<p>设置/var/spool/slurmctld目录所有者为slurm用户：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chown</span> slurm.slurm /var/spool/slurmctld </span><br></pre></td></tr></table></figure>

<p>启动slurmdbd服务：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@admin slurm]<span class="comment"># systemctl start slurmdbd</span></span><br><span class="line">[root@admin slurm]<span class="comment"># systemctl status slurmdbd</span></span><br><span class="line">● slurmdbd.service - Slurm DBD accounting daemon</span><br><span class="line">  Loaded: loaded (/usr/lib/systemd/system/slurmdbd.service; enabled; vendor preset: disabled)</span><br><span class="line">  Active: active (running)</span><br></pre></td></tr></table></figure>

<p>设置slurmdbd服务为开机自启动：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin slurm]<span class="comment"># systemctl enable slurmdbd</span></span><br></pre></td></tr></table></figure>

<p>设置Slurm中定义的集群名为hpccluster：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@admin slurm]<span class="comment"># sacctmgr add cluster hpccluster</span></span><br></pre></td></tr></table></figure>

<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">计算节点和用户登录节点设置slurmd服务</span><br><span class="line">无配置模式是Slurm的一项新特性（从20.02版起支持），可以允许计算节点和用户登录节点从slurmctld守护进程获取配置而无需采用 /etc/slurm 等目录下的本地配置文件。集群在Slurm控制节点上统一控制配置文件，计算节点、登录节点和其它集群节点只需通过 /lib/systemd/system/slurmd.service 文件配置slurmd服务启动参数，利用启动后的slurmd服务获取所需配置信息即可，而无需复制管理节点上的这些文件成为本地文件（降低文件配置不一样的风险）。</span><br><span class="line">https://slurm.schedmd.com/configless<span class="emphasis">_slurm.html</span></span><br></pre></td></tr></table></figure>

<p>[root@admin slurm]# cd /lib/systemd/system</p>
<p>建立 slurmd.service 文件，其内容为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Slurm node daemon</span><br><span class="line">After=munge.service network-online.target remote-fs.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line"><span class="comment"># ConditionPathExists=/etc/slurm/slurm.conf</span></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/slurmd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加--conf-server admin:6817设定slurmctld服务节点</span></span><br><span class="line">ExecStart=/usr/sbin/slurmd --conf-server admin:6817 -D -s <span class="variable">$SLURMD_OPTIONS</span></span><br><span class="line"></span><br><span class="line">ExecReload=/bin/kill -HUP <span class="variable">$MAINPID</span></span><br><span class="line">KillMode=process</span><br><span class="line">LimitNOFILE=131072</span><br><span class="line">LimitMEMLOCK=infinity</span><br><span class="line">LimitSTACK=infinity</span><br><span class="line">Delegate=<span class="built_in">yes</span></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>

<p>将该文件复制到各节点：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@admin slurm]<span class="comment"># cd /lib/systemd/system</span></span><br><span class="line">[root@admin system]<span class="comment"># scp slurmd.service node1:/lib/systemd/system</span></span><br><span class="line">[root@admin system]<span class="comment"># scp slurmd.service node2:/lib/systemd/system</span></span><br></pre></td></tr></table></figure>

<p>systemd的服务配置文件变更后，</p>
<p>各节点重新刷新服务内容后才能利用 systemctl 命令重启slurmd服务等：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart slurmd</span><br><span class="line">[root@admin system]<span class="comment"># systemctl daemon-reload</span></span><br><span class="line">[root@admin system]<span class="comment"># systemctl restart slurmd</span></span><br><span class="line">[root@admin system]<span class="comment"># systemctl status slurmd</span></span><br><span class="line">● slurmd.service - Slurm node daemon</span><br><span class="line">  Loaded: loaded (/usr/lib/systemd/system/slurmd.service; enabled; vendor preset: disabled)</span><br><span class="line">  Active: active (running) since Fri 2022-08-05 23:44:20 CST; 6s ago</span><br><span class="line"> Main PID: 3302 (slurmd)</span><br><span class="line">  Tasks: 1</span><br><span class="line">  Memory: 916.0K</span><br><span class="line">  CGroup: /system.slice/slurmd.service</span><br><span class="line">​      └─3302 /usr/sbin/slurmd --conf-server admin:6817 -D -s</span><br><span class="line">[root@node2 system]<span class="comment"># systemctl daemon-reload</span></span><br><span class="line">[root@node2 system]<span class="comment"># systemctl restart slurmd</span></span><br><span class="line">[root@node2 system]<span class="comment"># systemctl status slurmd</span></span><br></pre></td></tr></table></figure>

<p>设置记账账户和用户</p>
<p>增加none和test账户并赋予相应权限</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sacctmgr add account none,<span class="built_in">test</span> Cluster=MyCluster Description=<span class="string">&quot;My slurm cluster&quot;</span> Organization=<span class="string">&quot;USTC&quot;</span></span><br></pre></td></tr></table></figure>

<p>增加test1用户属于test账户</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sacctmgr -i add user test1 account=<span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<p>控制节点启动 slurmctld和slurmdbd（数据库在控制主机上）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]<span class="comment"># systemctl start  slurmctld</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl status slurmctld</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl enable slurmctld</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl start  slurmdbd</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl status slurmdbd</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl enable slurmdbd</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl start  slurmd</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl status slurmd</span></span><br><span class="line">[root@admin ~]<span class="comment"># systemctl enable slurmd</span></span><br></pre></td></tr></table></figure>

<p>计算节点只需要启动 slurmd</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start slurmd</span><br><span class="line">systemctl <span class="built_in">enable</span> slurmd</span><br></pre></td></tr></table></figure>

<p>上述查看服务状态是否running排查错误过程修改slurm.conf、slurmdbd.conf配置文件</p>
<h6 id="9、-测试slurm"><a href="#9、-测试slurm" class="headerlink" title="9、 测试slurm"></a>9、 测试slurm</h6><p>#查看集群</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sinfo</span><br></pre></td></tr></table></figure>

<p>#查看记账</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sacct</span><br></pre></td></tr></table></figure>

<h6 id="10、集群监控"><a href="#10、集群监控" class="headerlink" title="10、集群监控"></a>10、集群监控</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Grafana+Promethus</span><br></pre></td></tr></table></figure>

<p>计划友情给客户安装一套监控系统（CPU 内存 硬盘 网卡），暂不包含slurm可视化</p>
<p>[root@admin ~]# yum -y install slurm-gui-20.11.9-1.el7.x86_64 –skip-broken </p>
<h6 id="11、-应用程序"><a href="#11、-应用程序" class="headerlink" title="11、 应用程序"></a>11、 应用程序</h6><p>MPI编译环境，</p>
<p>ifort（Fortran编译器）</p>
<p>gcc（C语言编译器）</p>
<p>Python3.7（Anaconda版本，加第三方库sklearn、keras、tensorflow2、pytorch等）</p>
<p>matlab软件</p>
<h6 id="参考连接："><a href="#参考连接：" class="headerlink" title="参考连接："></a>参考连接：</h6><p><a target="_blank" rel="noopener" href="http://hmli.ustc.edu.cn/doc/linux/slurm-install/slurm-install.html#id31">http://hmli.ustc.edu.cn/doc/linux/slurm-install/slurm-install.html#id31</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/11/24/CentOS7_Slurm/" data-id="clw99wtq10001tha3ckkffsjg" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2022/11/24/diskless_CentOS7/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">HPC服务器集群配置CentOS 7.9无盘启动</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/11/">November 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">July 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/06/">June 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/11/24/CentOS7_Slurm/">CentOS7.9 install Slurm</a>
          </li>
        
          <li>
            <a href="/2022/11/24/diskless_CentOS7/">HPC服务器集群配置CentOS 7.9无盘启动</a>
          </li>
        
          <li>
            <a href="/2022/11/24/limit/">管理节点CPU和内存使用率超过60%自动kill进程</a>
          </li>
        
          <li>
            <a href="/2022/08/06/CentOS7_install_Slurm/">CentOS7.9安装Slurm计算调度集群</a>
          </li>
        
          <li>
            <a href="/2022/08/01/slurm1/">slurm示例</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2024 张东豪 zhangdonghao678@163.com<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>